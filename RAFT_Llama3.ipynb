{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNrSa1/uXsCPbm1jkqFiDrN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAFT: Retrieval Augmented Fine-Tuning\n",
        "### *Implementation of [arXiv:2403.10131](https://arxiv.org/pdf/2403.10131)*\n",
        "\n",
        "This notebook is an implementation of the **RAFT** paper from scratch. It demonstrates how to fine-tune a model to ignore \"distractor\" documents during Retrieval Augmented Generation (RAG).\n",
        "\n",
        "**Technical Note:** We utilize **Unsloth** for this implementation to optimize the fine-tuning process. This reduces VRAM usage by ~60% and accelerates training by 2x, allowing this entire pipeline to run on a free Google Colab T4 GPU."
      ],
      "metadata": {
        "id": "09O98smZuzSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w-VNnUps9Ru"
      },
      "outputs": [],
      "source": [
        "pip install unsloth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from datasets import Dataset\n",
        "\n",
        "# These represent the \"Oracle\" chunks retrieved from our Postgres Vector DB\n",
        "\n",
        "medical_facts = [\n",
        "    # Emergency Protocols\n",
        "    \"Sepsis Protocol (SEP-1): Administer 30mL/kg crystalloid fluid challenge within 3 hours of presentation for hypotension or lactate >= 4mmol/L.\",\n",
        "    \"Acute Coronary Syndrome (ACS): Dual antiplatelet therapy (Aspirin 325mg + P2Y12 inhibitor) should be administered immediately upon diagnosis of NSTEMI.\",\n",
        "    \"Stroke (Ischemic): tPA (Alteplase) is indicated within 4.5 hours of symptom onset if no hemorrhage is detected on CT head.\",\n",
        "    \"Anaphylaxis: First-line treatment is IM Epinephrine 0.01 mg/kg  (max 0.5 mg) into the mid-outer thigh, repeatable every 5-15 minutes.\",\n",
        "\n",
        "    # Chronic Management\n",
        "    \"Type 2 Diabetes: Metformin is first-line therapy. Add SGLT2 inhibitor if patient has established ASCVD or Heart Failure.\",\n",
        "    \"Hypertension: Stage 1 is 130-139/80-89 mmHg. Start monotherapy (ACEi/ARB, CCB, or Thiazide) if ASCVD risk > 10%.\",\n",
        "    \"Asthma: GINA 2023 guidelines recommend ICS-Formoterol as the preferred reliever for all severity steps, replacing SABA-only treatment.\",\n",
        "\n",
        "    # Drug Specifics\n",
        "    \"Vancomycin Dosing: Target trough levels of 15-20 mcg/mL for complicated infections (endocarditis, osteomyelitis, meningitis).\",\n",
        "    \"Warfarin Reversal: For major bleeding with elevated INR, administer 4-factor Prothrombin Complex Concentrate (PCC) and Vitamin K IV.\",\n",
        "    \"Hyperkalemia: For K+ > 6.5 with ECG changes, give Calcium Gluconate 1g IV immediately to stabilize cardiac membrane.\"\n",
        "]\n",
        "\n",
        "\n",
        "# 2. THE DISTRACTORS (Noise)\n",
        "# These simulate \"Bad Retrieval\" - documents that appeared in the search\n",
        "# but are irrelevant to the specific question asked.\n",
        "\n",
        "distractors = [\n",
        "    \"Hospital Policy 101: The cafeteria is open from 06:00 to 20:00. Staff discount applies with ID badge.\",\n",
        "    \"Visitor Policy: ICU visiting hours are restricted to immediate family members between 10:00 and 14:00.\",\n",
        "    \"IT Support: To reset your EMR password, contact the helpdesk at extension 5555. Do not share credentials.\",\n",
        "    \"Billing: ICD-10 code R07.9 (Chest pain, unspecified) requires additional documentation for reimbursement.\",\n",
        "    \"Parking: Staff parking in Lot B is prohibited during construction (Jan-Mar 2025). Use Lot C shuttle.\",\n",
        "    \"Pediatrics: The pediatric dosage for Amoxicillin is 20-40mg/kg/day divided q8h.\",\n",
        "    \"OB/GYN: Pre-eclampsia prophylaxis with Aspirin 81mg should start at 12 weeks gestation for high-risk patients.\",\n",
        "    \"Orthopedics: Post-op hip replacement patients require DVT prophylaxis for 35 days.\",\n",
        "    \"Grand Rounds: Dr. Oghalai will present on 'Cochlear Mechanics' this Friday at noon in the main auditorium.\",\n",
        "    \"Fire Safety: In case of Code Red, adhere to the RACE protocol (Rescue, Alarm, Contain, Extinguish).\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 3. RAFT DATA GENERATOR\n",
        "\n",
        "raft_data = []\n",
        "\n",
        "def get_context_from_postgres_simulation(target_fact):\n",
        "    \"\"\"\n",
        "    SIMULATING POSTGRES PGVECTOR RETRIEVAL:\n",
        "    In production, this function would look like this:\n",
        "\n",
        "    def get_real_postgres_context(question_embedding):\n",
        "        sql = \\\"\\\"\\\"\n",
        "        (\n",
        "            -- 1. Get the \"Gold\" Document (The closest vector)\n",
        "            SELECT content, embedding <=> %s as dist, 'gold' as type\n",
        "            FROM clinical_guidelines\n",
        "            ORDER BY dist ASC LIMIT 1\n",
        "        )\n",
        "        UNION ALL\n",
        "        (\n",
        "            -- 2. Get Distractors (Vectors that are 'kind of' close but not the answer, or random)\n",
        "            SELECT content, embedding <=> %s as dist, 'distractor' as type\n",
        "            FROM clinical_guidelines\n",
        "            WHERE embedding <=> %s > 0.4 -- Filter for things not TOO close\n",
        "            ORDER BY RANDOM() LIMIT 2\n",
        "        )\n",
        "        \\\"\\\"\\\"\n",
        "        cursor.execute(sql, (question_embedding, question_embedding, question_embedding))\n",
        "        return cursor.fetchall()\n",
        "    \"\"\"\n",
        "\n",
        "    # Since we don't have a live DB connection here, we simulate the result:\n",
        "    # 1 Gold Fact + 2 Random Distractors\n",
        "\n",
        "    noise_docs = random.sample(distractors, 2)\n",
        "    context_docs = noise_docs + [target_fact]\n",
        "    random.shuffle(context_docs) # Shuffle so model doesn't just learn \"Answer is always last\"\n",
        "    return context_docs\n",
        "\n",
        "\n",
        "# Manually pairing Questions with Facts for the Training Set\n",
        "# (In a real pipeline, we'd use GPT-4 to generate questions FROM the facts)\n",
        "\n",
        "qa_pairs = [\n",
        "    (\"What is the protocol for sepsis fluid resuscitation?\", medical_facts[0], \"Give 30mL/kg crystalloid within 3 hrs.\"),\n",
        "    (\"When should DAPT be started for NSTEMI?\", medical_facts[1], \"Immediately upon diagnosis.\"),\n",
        "    (\"What is the time window for tPA in ischemic stroke?\", medical_facts[2], \"Within 4.5 hours of symptom onset.\"),\n",
        "    (\"How do you treat anaphylaxis?\", medical_facts[3], \"IM Epinephrine 0.01 mg/kg immediately.\"),\n",
        "    (\"What is the first-line drug for Type 2 Diabetes?\", medical_facts[4], \"Metformin.\"),\n",
        "    (\"What are the BP targets for Stage 1 Hypertension?\", medical_facts[5], \"Treat if >130/80 and ASCVD risk >10%.\"),\n",
        "    (\"What is the preferred reliever for Asthma in GINA 2023?\", medical_facts[6], \"ICS-Formoterol.\"),\n",
        "    (\"What is the target trough for Vancomycin in endocarditis?\", medical_facts[7], \"15-20 mcg/mL.\"),\n",
        "    (\"How do you reverse Warfarin bleeding?\", medical_facts[8], \"4-factor PCC and IV Vitamin K.\"),\n",
        "    (\"What is the emergency treatment for Hyperkalemia with ECG changes?\", medical_facts[9], \"IV Calcium Gluconate 1g.\")\n",
        "]\n",
        "\n",
        "for question, fact, short_answer in qa_pairs:\n",
        "\n",
        "    # 1. Retrieve Context (Simulating the Postgres RAG step)\n",
        "    retrieved_docs = get_context_from_postgres_simulation(fact)\n",
        "\n",
        "    # 2. Format Context String\n",
        "    context_str = \"\\n\".join([f\"Document [{i+1}]: {doc}\" for i, doc in enumerate(retrieved_docs)])\n",
        "\n",
        "    # 3. Generate Chain of Thought (The RAFT Magic)\n",
        "    # We teach the model to explicitly cite the GOLD document and ignore the DISTRACTORS.\n",
        "\n",
        "    cot = f\"Reading the context, Document containing '{fact[:20]}...' discusses {short_answer}. The other documents regarding cafeteria hours or parking are irrelevant.\"\n",
        "\n",
        "    raft_sample = {\n",
        "        \"instruction\": \"You are an expert medical scribe. Answer the question based strictly on the provided context docs, citing your source.\",\n",
        "        \"input\": f\"Context:\\n{context_str}\\n\\nQuestion:\\n{question}\",\n",
        "        \"output\": f\"Thinking: {cot}\\nAnswer: {short_answer}\"\n",
        "    }\n",
        "    raft_data.append(raft_sample)\n",
        "\n",
        "# Convert to Dataset\n",
        "dataset = Dataset.from_list(raft_data)\n",
        "print(f\"Generated {len(dataset)} RAFT training samples.\")\n",
        "print(\"Sample Input:\\n\", dataset[0]['input'])"
      ],
      "metadata": {
        "id": "Ev05f4X1tKqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import builtins\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "builtins.psutil = psutil"
      ],
      "metadata": {
        "id": "vimsKJss1Hns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. FORMATTING THE PROMPT\n",
        "raft_prompt = \"\"\"### Instruction:\n",
        "{}\n",
        ",\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for inst, inp, out in zip(instructions, inputs, outputs):\n",
        "        text = raft_prompt.format(inst, inp, out) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "# Apply the format to the new dataset\n",
        "train_dataset = dataset.map(formatting_prompts_func, batched = True)\n"
      ],
      "metadata": {
        "id": "q-kFwg30EIVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. THE TRAINER (Fine-Tuning Loop)\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = 2048,\n",
        "    dataset_num_proc = 2,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"raft_outputs\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(\"Starting RAFT Fine-Tuning...\")\n",
        "trainer.train()\n",
        "print(\"Training Complete!\")"
      ],
      "metadata": {
        "id": "NklIoaWy1HeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. INFERENCE TEST\n",
        "\n",
        "# (ONLY Run AFTER the training step finishes)\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# A test case with distractors (for ex. lets try : Pizza & Parking)\n",
        "\n",
        "test_context = \"\"\"Context:\n",
        "Document [1]: The hospital cafeteria serves pizza on Fridays.\n",
        "Document [2]: Acute Coronary Syndrome (ACS): Dual antiplatelet therapy (Aspirin + P2Y12) should be administered immediately.\n",
        "Document [3]: Parking structure B is closed for maintenance.\n",
        "\n",
        "Question:\n",
        "When should DAPT be started for NSTEMI?\"\"\"\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    raft_prompt.format(\n",
        "        \"You are an expert medical scribe. Answer the question based strictly on the provided context docs, citing your source.\", # Instruction\n",
        "        test_context, # Input\n",
        "        \"\", # Output (Left blank for generation)\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True)\n",
        "\n",
        "\n",
        "# Decode the output and strip the prompt\n",
        "print(\"\\n=== MODEL OUTPUT ===\")\n",
        "print(tokenizer.batch_decode(outputs)[0].split(\"### Response:\")[-1])"
      ],
      "metadata": {
        "id": "0pUdZ5Kw2umc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. MINI-BATCH EVALUATION\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "eval_cases = [\n",
        "    {\n",
        "        \"topic\": \"Sepsis\",\n",
        "        \"context\": \"\"\"Document [A]: The cafetera closes at 8pm.\\nDocument [B]: Sepsis Protocol: Administer 30mL/kg crystalloid fluid within 3 hours.\\nDocument [C]: Dr. Smith is on vacation.\"\"\",\n",
        "        \"question\": \"What is the fluid resuscitation protocol for sepsis?\"\n",
        "    },\n",
        "    {\n",
        "        \"topic\": \"Stroke\",\n",
        "        \"context\": \"\"\"Document [A]: Stroke (Ischemic): tPA is indicated within 4.5 hours.\\nDocument [B]: Parking Lot C is for visitors only.\\nDocument [C]: To reset wifi password, call IT.\"\"\",\n",
        "        \"question\": \"What is the time window for tPA?\"\n",
        "    },\n",
        "    {\n",
        "        \"topic\": \"Anaphylaxis\",\n",
        "        \"context\": \"\"\"Document [A]: Fire drill at noon.\\nDocument [B]: Anaphylaxis: First-line treatment is IM Epinephrine 0.01 mg/kg.\\nDocument [C]: Bagels are available in the break room.\"\"\",\n",
        "        \"question\": \"What is the first-line treatment for anaphylaxis?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "print(\"Running Mini-Eval...\")\n",
        "for case in eval_cases:\n",
        "    inputs = tokenizer(\n",
        "        [\n",
        "            raft_prompt.format(\n",
        "                \"Answer strictly based on context.\",\n",
        "                f\"Context:\\n{case['context']}\\n\\nQuestion:\\n{case['question']}\",\n",
        "                \"\",\n",
        "            )\n",
        "        ], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "    response = tokenizer.batch_decode(outputs)[0].split(\"### Response:\")[-1].strip()\n",
        "\n",
        "    results.append({\n",
        "        \"Topic\": case['topic'],\n",
        "        \"Model Response\": response\n",
        "    })\n",
        "\n",
        "# RESULTS\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\n=== EVALUATION REPORT ===\")\n",
        "print(df.to_markdown(index=False))"
      ],
      "metadata": {
        "id": "qqSHv2_54ugv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}